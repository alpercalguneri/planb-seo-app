import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai

# --- SAYFA AYARLARI ---
st.set_page_config(
    page_title="PlanB Media Keyword Research Tool", 
    layout="wide", 
    page_icon="ğŸ…±ï¸"
)

# --- CSS AYARLARI ---
st.markdown("""
    <style>
    .main > div {padding-top: 1rem;}
    h1 {color: #333333;}
    .stMetric {background-color: #f9f9f9; padding: 10px; border-radius: 10px; border: 1px solid #eee;}
    </style>
    """, unsafe_allow_html=True)

# --- API BÄ°LGÄ°LERÄ° (SECRETS) ---
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    DFS_LOGIN = st.secrets["DFS_LOGIN"]
    DFS_PASSWORD = st.secrets["DFS_PASSWORD"]
except:
    st.error("LÃ¼tfen API anahtarlarÄ±nÄ±zÄ± secrets.toml dosyasÄ±na ekleyin.")
    st.stop()

# Gemini BaÅŸlat
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- ÃœLKE VE DÄ°L KONFÄ°GÃœRASYONU ---
# Her Ã¼lkenin kodu, dili ve o dile ait soru kalÄ±plarÄ±
COUNTRY_CONFIG = {
    "TÃ¼rkiye": {
        "loc": 2792, "lang": "tr", "lang_name": "Turkish",
        "questions": ["nasÄ±l", "nedir", "ne kadar", "nerede", "kim", "hangi", "kaÃ§", "mÄ±", "mi", "neden", "niye"]
    },
    "ABD": {
        "loc": 2840, "lang": "en", "lang_name": "English",
        "questions": ["how", "what", "where", "who", "which", "why", "when", "can", "is", "do"]
    },
    "Ä°ngiltere": {
        "loc": 2826, "lang": "en", "lang_name": "English",
        "questions": ["how", "what", "where", "who", "which", "why", "when", "can", "is", "do"]
    },
    "Almanya": {
        "loc": 2276, "lang": "de", "lang_name": "German",
        "questions": ["wie", "was", "wo", "wer", "warum", "wann", "welche", "kann", "ist"]
    }
}

# --- FONKSÄ°YONLAR ---

def get_dataforseo_data(keyword, loc, lang):
    """
    DataForSEO'dan veri Ã§eker.
    """
    url = "https://api.dataforseo.com/v3/dataforseo_labs/google/keyword_ideas/live"
    
    payload = [{
        "keywords": [keyword], 
        "location_code": loc, 
        "language_code": lang, 
        "limit": 700, 
        "include_seed_keyword": True
    }]
    
    try:
        response = requests.post(url, auth=(DFS_LOGIN, DFS_PASSWORD), json=payload)
        res = response.json()

        if response.status_code == 200 and res.get('tasks') and res['tasks'][0]['result']:
            items = res['tasks'][0]['result'][0]['items']
            data = []
            
            for i in items:
                # KD'yi artÄ±k Ã§eksek de tabloda gÃ¶stermeyeceÄŸiz, ama filtre iÃ§in tutabiliriz
                kw_info = i.get('keyword_info', {})
                
                data.append({
                    "Keyword": i['keyword'],
                    "Volume": kw_info.get('search_volume', 0),
                    "CPC": kw_info.get('cpc', 0),
                    # KD'yi kaldÄ±rdÄ±k
                })
            
            df = pd.DataFrame(data)
            return df
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"API HatasÄ±: {e}")
        return None

def filter_keywords(df, match_type, seed_keyword, question_list):
    """
    Filtreleme MantÄ±ÄŸÄ± (Dinamik Soru Listesi ile)
    """
    if df.empty:
        return df
        
    seed_lower = seed_keyword.lower()
    
    if match_type == "Phrase Match (SÄ±ralÄ±)":
        return df[df['Keyword'].str.contains(seed_lower, na=False)]
        
    elif match_type == "Exact Match (Tam)":
        return df[df['Keyword'] == seed_lower]
        
    elif match_type == "Questions (Sorular)":
        # Sadece seÃ§ilen Ã¼lkenin soru kalÄ±plarÄ±nÄ± ve ana kelimeyi iÃ§erenleri getir
        # Ã–rn: "iphone fiyatÄ± nedir" (Hem iphone hem nedir iÃ§ermeli ki alakalÄ± olsun)
        
        # 1. AdÄ±m: Soru kelimelerinden en az biri geÃ§meli
        mask_questions = df['Keyword'].str.contains('|'.join(question_list), na=False, case=False)
        
        # 2. AdÄ±m: Anahtar kelime de iÃ§inde geÃ§meli (Alaka dÃ¼zeyi iÃ§in)
        mask_seed = df['Keyword'].str.contains(seed_lower, na=False)
        
        return df[mask_questions & mask_seed]
        
    else: # Broad Match
        return df

# --- ARAYÃœZ ---

# 1. LOGO YERLEÅÄ°MÄ°
# 'logo.png' dosyasÄ±nÄ±n main.py ile aynÄ± klasÃ¶rde olmasÄ± lazÄ±m.
col_logo, col_title = st.columns([1, 4])
with col_logo:
    try:
        st.image("logo.png", width=180) 
    except:
        st.warning("logo.png bulunamadÄ±.") # Dosya yoksa uyarÄ± verir ama Ã§Ã¶kmez

with col_title:
    st.title("Keyword Research Tool (V1.0)")
    st.markdown("Powered by **DataForSEO** & **Gemini AI**")

st.divider()

# Sidebar
with st.sidebar:
    st.header("Analiz Parametreleri")
    
    keyword_input = st.text_input("Anahtar Kelime", "iphone 15")
    url_input = st.text_input("Hedef URL (Opsiyonel)", "")
    
    # Ãœlke SeÃ§imi
    country_selected = st.selectbox("Hedef Ãœlke", list(COUNTRY_CONFIG.keys()))
    
    # SeÃ§ilen Ã¼lkenin ayarlarÄ±nÄ± al
    settings = COUNTRY_CONFIG[country_selected]
    
    st.divider()
    
    # Match Type SeÃ§ici
    match_type = st.radio(
        "EÅŸleme TÃ¼rÃ¼ (Filtre)",
        ["Broad Match (GeniÅŸ)", "Phrase Match (SÄ±ralÄ±)", "Exact Match (Tam)", "Questions (Sorular)"],
        index=0,
        help="Questions: Sadece seÃ§ilen dildeki soru kalÄ±plarÄ±nÄ± (Ã¶rn: nedir, how, wie) iÃ§eren kelimeleri getirir."
    )
    
    btn_analyze = st.button("Analizi BaÅŸlat", type="primary")

# Ana AkÄ±ÅŸ
if btn_analyze:
    if not DFS_PASSWORD or "BURAYA" in DFS_PASSWORD:
        st.error("API Åifreleri girilmemiÅŸ.")
    else:
        with st.spinner(f"ğŸš€ {country_selected} verileri taranÄ±yor..."):
            
            # 1. Veriyi Ã‡ek
            raw_df = get_dataforseo_data(keyword_input, settings["loc"], settings["lang"])
            
            if raw_df is not None and not raw_df.empty:
                # 2. Filtrele (Dinamik soru listesini gÃ¶nderiyoruz)
                df_filtered = filter_keywords(raw_df, match_type, keyword_input, settings["questions"])
                
                # SÄ±ralama
                df_filtered = df_filtered.sort_values(by="Volume", ascending=False).reset_index(drop=True)
                
                if df_filtered.empty:
                    st.warning(f"'{match_type}' kriterine uygun kelime bulunamadÄ±.")
                else:
                    # 3. Metrikler
                    c1, c2, c3 = st.columns(3)
                    
                    c1.metric("Listelenen Kelime", len(df_filtered))
                    c1.markdown(f"<small>Dil: {settings['lang_name']} | Filtre: {match_type}</small>", unsafe_allow_html=True)
                    
                    c2.metric("Toplam Hacim", f"{df_filtered['Volume'].sum():,}")
                    
                    top_kw = df_filtered.iloc[0]['Keyword']
                    c3.metric("En PopÃ¼ler", top_kw)
                    
                    st.divider()
                    
                    # 4. Tablo (KD Ã‡Ä±karÄ±ldÄ±)
                    st.subheader("ğŸ“‹ Anahtar Kelime Listesi")
                    
                    st.dataframe(
                        df_filtered,
                        use_container_width=True,
                        column_config={
                            "Keyword": "Anahtar Kelime",
                            "Volume": st.column_config.NumberColumn("Hacim", format="%d"),
                            "CPC": st.column_config.NumberColumn("CPC ($)", format="$%.2f")
                        },
                        height=500
                    )
                    
                    # CSV Ä°ndirme
                    csv = df_filtered.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="ğŸ“¥ Listeyi CSV Olarak Ä°ndir",
                        data=csv,
                        file_name=f"planb_{keyword_input}_{settings['lang']}.csv",
                        mime="text/csv"
                    )
                    
                    # 5. AI Analizi (GELÄ°ÅMÄ°Å PROMPT)
                    st.divider()
                    st.subheader(f"ğŸ¤– PlanB AI Stratejisi ({country_selected})")
                    
                    top_5_rel = ", ".join(df_filtered.head(5)['Keyword'].tolist())
                    url_context = f"Web Sitesi: {url_input}" if url_input else ""
                    
                    prompt = f"""
                    Sen PlanB Media ajansÄ±nÄ±n Global SEO Stratejistisin.
                    
                    ANALÄ°Z DETAYLARI:
                    - Hedef Ãœlke: {country_selected}
                    - Konu: {keyword_input}
                    - {url_context}
                    - En Hacimli Kelimeler: {top_5_rel}
                    
                    GÃ–REV:
                    Bu verileri ve {country_selected} Ã¼lkesindeki gÃ¼ncel trendleri dÃ¼ÅŸÃ¼nerek 5 adet Blog BaÅŸlÄ±ÄŸÄ± Ã¶ner.
                    
                    KURALLAR:
                    1. BaÅŸlÄ±klar kesinlikle {settings['lang_name']} ({settings['lang'].upper()}) dilinde olmalÄ±.
                    2. "Neden?" aÃ§Ä±klamalarÄ± kesinlikle TÃœRKÃ‡E olmalÄ±.
                    3. BaÅŸlÄ±klar {country_selected} kullanÄ±cÄ±larÄ±nÄ±n arama niyetine ve trendlerine uygun olmalÄ±.
                    
                    Ã‡IKTI FORMATI:
                    1. [BaÅŸlÄ±k ({settings['lang_name']})]
                       - ğŸ¯ Odak: [Anahtar Kelime]
                       - ğŸ’¡ Neden: [TÃ¼rkÃ§e stratejik aÃ§Ä±klama]
                    
                    (Toplam 5 tane)
                    """
                    
                    try:
                        response = model.generate_content(prompt)
                        st.info(response.text)
                    except Exception as e:
                        st.warning(f"AI YanÄ±tÄ± alÄ±namadÄ±: {e}")
            else:
                st.error("Veri bulunamadÄ±. LÃ¼tfen kelimeyi veya Ã¼lkeyi kontrol edin.")