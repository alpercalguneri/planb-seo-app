import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
from google.oauth2 import service_account
from googleapiclient.discovery import build
import datetime
import altair as alt # G√∂rselle≈ütirme i√ßin eklendi

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="PlanB Media SEO AI", layout="wide", page_icon="üÖ±Ô∏è")

# --- CSS VE TASARIM ---
st.markdown("""
    <style>
    .main > div {padding-top: 2rem;}
    .stChatInput {position: fixed; bottom: 3rem;}
    .block-container {padding-bottom: 5rem;}
    h1 {color: #d32f2f;}
    /* Metrik kutularƒ±nƒ± g√ºzelle≈ütir */
    div[data-testid="stMetric"] {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- API Bƒ∞LGƒ∞LERƒ∞ ---
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    DFS_LOGIN = st.secrets["DFS_LOGIN"]
    DFS_PASSWORD = st.secrets["DFS_PASSWORD"]
    GSC_CREDENTIALS = {
        "type": "service_account",
        "project_id": st.secrets["GSC_PROJECT_ID"],
        "private_key_id": "optional",
        "private_key": st.secrets["GSC_PRIVATE_KEY"].replace('\\n', '\n'),
        "client_email": st.secrets["GSC_CLIENT_EMAIL"],
        "client_id": "optional",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": f"https://www.googleapis.com/robot/v1/metadata/x509/{st.secrets['GSC_CLIENT_EMAIL']}"
    }
except Exception as e:
    st.error(f"Secret Hatasƒ±: {e}. L√ºtfen secrets.toml dosyasƒ±nƒ± kontrol edin.")
    st.stop()

# AI Modelini Ba≈ülat
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash') # G√ºncel ve hƒ±zlƒ± model

# --- YARDIMCI FONKSƒ∞YONLAR ---

def classify_intent(keyword):
    """
    Basit kural tabanlƒ± Search Intent (Niyet) analizi.
    Bunu AI ile yapmak daha maliyetli olacaƒüƒ± i√ßin kural tabanlƒ± hƒ±zlƒ± √ß√∂z√ºm.
    """
    k = keyword.lower()
    if any(x in k for x in ['satƒ±n al', 'fiyat', 'ucuz', 'sipari≈ü', 'kiralƒ±k', 'buy', 'price']):
        return "Transactional (ƒ∞≈ülem)"
    elif any(x in k for x in ['en iyi', 'kar≈üƒ±la≈ütƒ±rma', 'yorum', 'inceleme', 'vs', 'best', 'review']):
        return "Commercial (Ticari)"
    elif any(x in k for x in ['nedir', 'nasƒ±l', 'ne demek', 'kimdir', 'tarifi', 'rehberi', 'what is', 'how to']):
        return "Informational (Bilgi)"
    else:
        return "Navigational/General"

def extract_date_range_from_prompt(user_prompt):
    today = datetime.date.today()
    prompt = f"""
    Bug√ºn√ºn tarihi: {today}
    Kullanƒ±cƒ± Girdisi: "{user_prompt}"
    G√ñREV: Kullanƒ±cƒ±nƒ±n c√ºmlesinden analiz etmek istediƒüi TARƒ∞H ARALIƒûINI √ßƒ±kar.
    KURALLAR:
    1. Belirli bir tarih varsa (√∂rn: "Ekim 2023") o tarihleri hesapla.
    2. Tarih yoksa (√∂rn: "D√º≈ü√º≈ü var mƒ±?"), varsayƒ±lan olarak SON 28 G√úN√ú al.
    3. √áƒ±ktƒ± formatƒ± SADECE: "YYYY-MM-DD|YYYY-MM-DD". Ba≈üka metin yazma.
    """
    try:
        response = model.generate_content(prompt)
        dates = response.text.strip().split('|')
        if len(dates) == 2:
            return dates[0], dates[1]
    except:
        pass
    start = today - datetime.timedelta(days=28)
    return str(start), str(today)

def get_gsc_raw_data(site_url, start_date, end_date):
    try:
        creds = service_account.Credentials.from_service_account_info(
            GSC_CREDENTIALS, scopes=['https://www.googleapis.com/auth/webmasters.readonly']
        )
        service = build('searchconsole', 'v1', credentials=creds)
        request = {
            'startDate': start_date,
            'endDate': end_date,
            'dimensions': ['query', 'page'], 
            'rowLimit': 1000 
        }
        response = service.searchanalytics().query(siteUrl=site_url, body=request).execute()
        if 'rows' in response:
            data = []
            for row in response['rows']:
                data.append({
                    "Query": row['keys'][0],
                    "Page": row['keys'][1],
                    "Clicks": row['clicks'],
                    "Impressions": row['impressions'],
                    "CTR": round(row['ctr'] * 100, 2),
                    "Position": round(row['position'], 1)
                })
            return pd.DataFrame(data)
        return pd.DataFrame()
    except Exception as e:
        return None

def get_dfs_data(keyword, loc, lang):
    """
    DataForSEO API: 'related_keywords' endpoint'i daha zengin sonu√ßlar verebilir 
    ancak ≈üimdilik 'keyword_ideas' √ºzerinden KD ve detaylarƒ± alacaƒüƒ±z.
    """
    url = "https://api.dataforseo.com/v3/dataforseo_labs/google/keyword_ideas/live"
    # limit'i biraz artƒ±rdƒ±k
    payload = [{
        "keywords": [keyword], 
        "location_code": loc, 
        "language_code": lang, 
        "limit": 600, 
        "include_seed_keyword": True,
        "include_serp_info": False # Hƒ±z i√ßin kapalƒ±, detay gerekirse a√ßƒ±labilir
    }]
    
    try:
        response = requests.post(url, auth=(DFS_LOGIN, DFS_PASSWORD), json=payload)
        res = response.json()
        
        if response.status_code == 200 and res.get('tasks') and res['tasks'][0]['result']:
            items = res['tasks'][0]['result'][0]['items']
            data = []
            for i in items:
                kw_info = i.get('keyword_info', {})
                
                # Semrush/Ahrefs KD (Keyword Difficulty) mantƒ±ƒüƒ±
                # DataForSEO 'competition_index' verir (0-100). 
                kd = i.get('keyword_properties', {}).get('keyword_difficulty', kw_info.get('competition_index', 0))
                
                data.append({
                    "Keyword": i['keyword'],
                    "Volume": kw_info.get('search_volume', 0),
                    "CPC": kw_info.get('cpc', 0),
                    "KD %": kd, # Keyword Difficulty
                    "Competition": kw_info.get('competition_level', 'Unknown'),
                    "Trend": kw_info.get('monthly_searches', []) # Opsiyonel: Trend grafiƒüi i√ßin
                })
            
            df = pd.DataFrame(data)
            # Intent Kolonu Ekle
            df['Intent'] = df['Keyword'].apply(classify_intent)
            return df
        return pd.DataFrame()
    except Exception as e:
        st.error(f"API Hatasƒ±: {e}")
        return None

# --- ANA UYGULAMA YAPISI ---

with st.sidebar:
    st.title("üÖ±Ô∏è PlanB SEO Tools")
    st.markdown("---")
    app_mode = st.radio("Ara√ß Se√ßimi", ["üîç Keyword Research (Pro)", "ü§ñ GSC AI Chatbot"])
    st.markdown("---")
    st.caption("v2.0 - Enhanced Metrics")

# ======================================================
# MOD 1: KEYWORD RESEARCH (PRO)
# ======================================================
if app_mode == "üîç Keyword Research (Pro)":
    st.title("üîç Keyword Magic Tool (DataForSEO Entegre)")
    st.markdown("Semrush/Ahrefs benzeri veri analizi ve i√ßerik stratejisi.")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        keyword_input = st.text_input("Anahtar Kelime", placeholder="√ñrn: elektrikli s√ºp√ºrge")
    with col2:
        country_map = {"T√ºrkiye": 2792, "ABD": 2840, "ƒ∞ngiltere": 2826}
        country = st.selectbox("Lokasyon", list(country_map.keys()))
    with col3:
        match_type = st.selectbox("E≈üleme T√ºr√º", ["Geni≈ü E≈üleme (Broad)", "Tam E≈üleme (Phrase)"])
    
    with st.expander("‚öôÔ∏è Geli≈ümi≈ü Filtreler & Rakipler", expanded=False):
        c1, c2 = st.columns(2)
        min_vol = c1.number_input("Min. Hacim", value=100, step=100)
        max_kd = c2.number_input("Maks. KD % (Zorluk)", value=80, step=5)
        target_website = st.text_input("Hedef Site (Opsiyonel)", placeholder="https://markam.com")
    
    if st.button("Analiz Et", type="primary") and keyword_input:
        with st.spinner(f"'{keyword_input}' i√ßin pazar verileri √ßekiliyor..."):
            
            # 1. Veriyi √áek
            lang = "tr" if country == "T√ºrkiye" else "en"
            df = get_dfs_data(keyword_input, country_map[country], lang)
            
            if df is not None and not df.empty:
                # 2. Filtreleme Mantƒ±ƒüƒ±
                if match_type == "Tam E≈üleme (Phrase)":
                    df = df[df['Keyword'].str.contains(keyword_input.lower())]
                
                # Sayƒ±sal Filtreler
                df = df[df['Volume'] >= min_vol]
                df = df[df['KD %'] <= max_kd]
                
                # Sƒ±ralama (Hacim ve KD √∂ncelikli)
                df = df.sort_values(by="Volume", ascending=False).reset_index(drop=True)
                
                if df.empty:
                    st.warning("Filtreleme kriterlerine uygun kelime bulunamadƒ±. Filtreleri gev≈üetin.")
                else:
                    # --- √úST METRƒ∞KLER ---
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("Bulunan Kelime", len(df))
                    m1.caption("Filtrelenmi≈ü")
                    m2.metric("Toplam Hacim", f"{df['Volume'].sum():,}")
                    m3.metric("Ort. KD %", round(df['KD %'].mean(), 1))
                    m4.metric("Potansiyel Tƒ±klama", f"{(df['Volume'].sum() * 0.45):,.0f}") # Tahmini
                    
                    st.markdown("---")
                    
                    # --- GRAFƒ∞K (AHREFS TARZI BUBBLE CHART) ---
                    st.subheader("üìä Keyword Landscape")
                    
                    chart_data = df.head(50) # Grafik ≈üi≈ümesin diye top 50
                    
                    scatter = alt.Chart(chart_data).mark_circle().encode(
                        x=alt.X('KD %', title='Keyword Difficulty (Zorluk)'),
                        y=alt.Y('Volume', title='Search Volume (Hacim)'),
                        size=alt.Size('CPC', title='CPC', scale=alt.Scale(range=[50, 1000])),
                        color=alt.Color('Intent', legend=alt.Legend(title="Niyet")),
                        tooltip=['Keyword', 'Volume', 'KD %', 'CPC', 'Intent']
                    ).properties(height=400).interactive()
                    
                    st.altair_chart(scatter, use_container_width=True)
                    
                    # --- TABLO ---
                    st.subheader("üìã Kelime Listesi")
                    
                    # Dataframe'i daha ≈üƒ±k g√∂sterelim
                    st.dataframe(
                        df[['Keyword', 'Intent', 'Volume', 'KD %', 'CPC', 'Competition']],
                        use_container_width=True,
                        column_config={
                            "Volume": st.column_config.NumberColumn("Hacim", format="%d"),
                            "KD %": st.column_config.ProgressColumn("Zorluk", min_value=0, max_value=100, format="%d%%"),
                            "CPC": st.column_config.NumberColumn("CPC ($)", format="$%.2f"),
                        },
                        height=400
                    )
                    
                    # --- STRATEJƒ∞ ALANI (AI) ---
                    st.markdown("---")
                    st.subheader("üß† AI Content Strategy")
                    
                    # AI'ya daha zengin veri g√∂nderelim
                    top_keywords = df.head(15).to_csv(index=False)
                    intent_dist = df['Intent'].value_counts().to_string()
                    
                    prompt = f"""
                    Sen Kƒ±demli bir SEO Stratejistisin.
                    
                    ANALƒ∞Z VERƒ∞Sƒ∞:
                    - Konu: {keyword_input}
                    - Hedef Site: {target_website}
                    - Niyet Daƒüƒ±lƒ±mƒ±: {intent_dist}
                    - En Hacimli Kelimeler (CSV):
                    {top_keywords}
                    
                    G√ñREV:
                    1. Bu verisetine g√∂re 3 adet 'D√º≈ü√ºk Rekabet - Y√ºksek Hacim' (Low Hanging Fruit) fƒ±rsatƒ±nƒ± belirle.
                    2. Hangi i√ßerik t√ºr√ºne (Blog, Kategori, √úr√ºn sayfasƒ±) odaklanmalƒ±yƒ±z?
                    3. Tablodaki verilere dayanarak kƒ±sa bir i√ßerik briefi olu≈ütur.
                    """
                    
                    if st.button("üöÄ AI Strateji Olu≈ütur"):
                        with st.spinner("Gemini verileri yorumluyor..."):
                            response = model.generate_content(prompt)
                            st.markdown(response.text)
            
            else:
                st.error("API'den veri alƒ±namadƒ± veya limit a≈üƒ±mƒ±.")

# ======================================================
# MOD 2: GSC AI CHATBOT
# ======================================================
elif app_mode == "ü§ñ GSC AI Chatbot":
    st.title("ü§ñ GSC AI Data Analyst")
    st.caption("Veri aralƒ±ƒüƒ±nƒ± kendi belirleyen akƒ±llƒ± asistan.")
    
    gsc_property = st.text_input("GSC M√ºlk URL'si", placeholder="sc-domain:markam.com veya https://markam.com/")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "current_gsc_data_range" not in st.session_state:
        st.session_state.current_gsc_data_range = None
    if "gsc_dataframe" not in st.session_state:
        st.session_state.gsc_dataframe = None

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Soru sor... (√ñrn: Ge√ßen ay en √ßok d√º≈üen sayfalar?)"):
        
        if not gsc_property:
            st.error("L√ºtfen √∂nce GSC M√ºlk adresini girin.")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.spinner("Analiz yapƒ±lƒ±yor..."):
                start_date, end_date = extract_date_range_from_prompt(prompt)
                current_range = f"{start_date}|{end_date}"
                
                # Veri yeni mi √ßekilmeli?
                if st.session_state.current_gsc_data_range != current_range:
                    df_gsc = get_gsc_raw_data(gsc_property, start_date, end_date)
                    
                    if df_gsc is not None and not df_gsc.empty:
                        st.session_state.gsc_dataframe = df_gsc
                        st.session_state.current_gsc_data_range = current_range
                        system_msg = f"üìÖ **{start_date}** - **{end_date}** verisi y√ºklendi ({len(df_gsc)} satƒ±r)."
                        st.session_state.messages.append({"role": "assistant", "content": system_msg})
                        st.markdown(f"*{system_msg}*")
                    else:
                        err_msg = "Veri bulunamadƒ± veya API hatasƒ±."
                        st.session_state.messages.append({"role": "assistant", "content": err_msg})
                        st.markdown(err_msg)
                        st.stop()
                
                # AI Yanƒ±tƒ±
                if st.session_state.gsc_dataframe is not None:
                    df = st.session_state.gsc_dataframe
                    
                    # Veriyi k√º√ß√ºlt√ºp AI'ya √∂zet ge√ßiyoruz
                    total_clicks = df['Clicks'].sum()
                    top_queries = df.nlargest(30, 'Clicks')[['Query', 'Clicks', 'Position']].to_markdown()
                    top_pages = df.groupby('Page')['Clicks'].sum().nlargest(10).to_markdown()
                    
                    ai_context = f"""
                    D√ñNEM: {start_date} ile {end_date} arasƒ±.
                    TOPLAM TIKLAMA: {total_clicks}
                    
                    EN ƒ∞Yƒ∞ SORGULAR:
                    {top_queries}
                    
                    EN ƒ∞Yƒ∞ SAYFALAR:
                    {top_pages}
                    """
                    
                    full_prompt = f"""
                    Sen SEO Analistisin. Veri seti:
                    {ai_context}
                    
                    Soru: "{prompt}"
                    
                    Yanƒ±tƒ±nda mutlaka sayƒ±sal verileri kullan. Kƒ±sa ve net ol.
                    """
                    
                    try:
                        response = model.generate_content(full_prompt)
                        ai_reply = response.text
                        st.session_state.messages.append({"role": "assistant", "content": ai_reply})
                        with st.chat_message("assistant"):
                            st.markdown(ai_reply)
                    except Exception as e:
                        st.error(f"AI Hatasƒ±: {e}")
